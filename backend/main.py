from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
import tempfile
import os
import subprocess
import openai
from datetime import datetime

print("‚úÖ API DO OUVIESCREVI INICIADA")
print("üîë Chave carregada:", bool(os.getenv("OPENAI_API_KEY")))

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def format_segments(segments):
    def format_time(seconds):
        m, s = divmod(int(seconds), 60)
        return f"[{m:02d}:{s:02d}]"
    formatted_text = ""
    for s in segments:
        timestamp = format_time(s.start)
        formatted_text += f"{timestamp} {s.text.strip()}\n\n"
    return formatted_text.strip()

@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...)):
    print(f"üì• [{datetime.now()}] Upload recebido: {file.filename}")

    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        contents = await file.read()
        tmp.write(contents)
        tmp_path = tmp.name

    audio_path = tmp_path + ".wav"

    try:
        # Usa ffmpeg diretamente (melhor suporte para formatos como webm, mp4 etc.)
        command = [
            "ffmpeg",
            "-i", tmp_path,
            "-ar", "16000",  # amostragem
            "-ac", "1",      # mono
            "-c:a", "pcm_s16le",  # formato WAV compat√≠vel
            audio_path,
            "-y"
        ]
        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
    except Exception as e:
        print(f"‚ùå Erro ao converter √°udio ({file.filename}): {e}")
        return {"error": f"Erro ao converter √°udio: {str(e)}"}

    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json"
            )
    except Exception as e:
        print(f"‚ùå Erro ao transcrever √°udio ({file.filename}): {e}")
        return {"error": f"Erro ao transcrever: {str(e)}"}

    os.remove(tmp_path)
    os.remove(audio_path)

    print(f"‚úÖ [{datetime.now()}] Transcri√ß√£o conclu√≠da com sucesso: {file.filename}")

    formatted = format_segments(transcript.segments)
    return {
        "transcription": transcript.text,
        "formatted": formatted
    }
from pydantic import BaseModel
from fastapi import Request

class SummarizeRequest(BaseModel):
    text: str
    token: str = ""
    mode: str = "normal"


@app.post("/summarize")
async def summarize(req: SummarizeRequest, request: Request):
    if req.token != os.getenv("ADMIN_TOKEN", "ouviescrevi2025@resumo"):
        return {"error": "Token inv√°lido ou ausente."}

    if req.mode == "minuta":
        prompt = (
            "A partir da seguinte transcri√ß√£o de uma reuni√£o ou conversa, gera uma minuta clara e organizada "
            "em formato de t√≥picos. Inclui:\n"
            "- T√≥picos discutidos\n"
            "- Decis√µes tomadas\n"
            "- Respons√°veis (se mencionados)\n"
            "- A√ß√µes a realizar\n\n"
            f"Transcri√ß√£o:\n{req.text}"
        )
    else:
        prompt = f"Resume de forma clara e concisa a seguinte transcri√ß√£o:\n\n{req.text}"

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                { "role": "system", "content": "√âs um assistente que resume transcri√ß√µes de √°udio." },
                { "role": "user", "content": prompt }
            ],
            temperature=0.5,
            max_tokens=400
        )
        summary = response.choices[0].message.content.strip()
        return { "summary": summary }

    except Exception as e:
        print("‚ùå Erro ao gerar resumo:", e)
        return { "error": str(e) }


from fastapi import HTTPException  # certifica-te que est√° importado

@app.post("/translate")
async def translate_text(request: Request):
    data = await request.json()
    text = data.get("text")
    language = data.get("language")
    token = data.get("token")

    if token != "ouviescrevi2025@resumo":
        raise HTTPException(status_code=403, detail="Token inv√°lido.")

    # ‚úÖ Lista de idiomas suportados (em min√∫sculas)
    idiomas_suportados = ["ingl√™s", "espanhol", "franc√™s", "alem√£o", "italiano", "portugu√™s"]

    if language.lower() not in idiomas_suportados:
        return { "error": f"Idioma n√£o suportado: {language}" }

    # ‚úÖ Prompt para tradu√ß√£o
    prompt = f"Traduz o seguinte texto para {language}:\n\n{text}"

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                { "role": "system", "content": f"Traduz o texto para {language}." },
                { "role": "user", "content": text }
            ],
            temperature=0.3
        )

        translated = response.choices[0].message.content.strip()
        return { "translation": translated }

    except Exception as e:
        print("‚ùå Erro ao traduzir:", e)
        return { "error": str(e) }

from fastapi import FastAPI, Request
from pydantic import BaseModel
from openai import OpenAI
import os



# Modelo da requisi√ß√£o
class ClassifyRequest(BaseModel):
    text: str
    token: str

@app.post("/classify")
async def classify_content(request: ClassifyRequest):
    if request.token != "ouviescrevi2025@resumo":
        return {"error": "Token inv√°lido"}

    prompt = (
        "Classifica o tipo de conte√∫do abaixo como uma das seguintes op√ß√µes:\n"
        "- Entrevista\n- Aula\n- Podcast\n- Reuni√£o\n- Apresenta√ß√£o\n- Testemunho\n- Conversa informal\n\n"
        f"Texto:\n{request.text}\n\n"
        "Responde s√≥ com o tipo mais prov√°vel."
    )

    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=20
        )

        tipo = response.choices[0].message.content.strip()
        return {"type": tipo}

    except Exception as e:
        return {"error": str(e)}


@app.post("/correct")
async def correct_text(req: Request):
    data = await req.json()
    text = data.get("text", "")
    token = data.get("token")

    if token != "ouviescrevi2025@resumo":
        return {"error": "Token inv√°lido"}

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Corrige ortografia e gram√°tica do texto. Mant√©m o conte√∫do original."},
                {"role": "user", "content": text}
            ]
        )
        corrected = response.choices[0].message.content
        return {"corrected": corrected.strip()}
    except Exception as e:
        print("‚ùå Erro ao corrigir:", e)
        return {"error": str(e)}
